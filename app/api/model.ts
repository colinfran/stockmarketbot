/**
 * The LLM model used for all AI requests.
 *
 * `xai/grok-4-fast-reasoning`:
 * - High-speed variant of Grok-4 with enhanced reasoning ability
 * - Supports long context windows (up to ~2M tokens)
 * - Good for multi-step reasoning, analysis, and structured output
 * - More cost-efficient than the full Grok-4 reasoning model
 */

export const currentModel = "xai/grok-4-fast-reasoning"
